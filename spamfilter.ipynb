{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 label                                               text  \\\n",
      "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
      "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
      "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
      "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
      "\n",
      "   label_num  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          0  \n",
      "(5171, 4)\n",
      "Index(['Unnamed: 0', 'label', 'text', 'label_num'], dtype='object')\n",
      "(5171, 4)\n",
      "Unnamed: 0    0\n",
      "label         0\n",
      "text          0\n",
      "label_num     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "#Load the data from https://www.kaggle.com/datasets/venky73/spam-mails-dataset\n",
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "print(df.head(5)) \n",
    "df.head(5);\n",
    "\n",
    "#Print the shape of the df\n",
    "print(df.shape)\n",
    "\n",
    "#Get columnnames\n",
    "print(df.columns)\n",
    "\n",
    "#Check for duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "print(df.shape)\n",
    "\n",
    "#Show number of missign (NAN, NAN, na) data for each colum\n",
    "print(df.isnull().sum()) \n",
    "\n",
    "#Download the stopwords\n",
    "def process_text(text): \n",
    "    #1 remove punctuation\n",
    "    #2 remove stopwords\n",
    "    #3 return list of clean text words\n",
    "\n",
    "    nopunc = [char for char in text if char not in string.punctuation] \n",
    "    nopunc = ''.join(nopunc) \n",
    "    \n",
    "    #returns csv without punction\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Subject, enron, methanol, meter, 988291, foll...\n",
       "1    [Subject, hpl, nom, january, 9, 2001, see, att...\n",
       "2    [Subject, neon, retreat, ho, ho, ho, around, w...\n",
       "3    [Subject, photoshop, windows, office, cheap, m...\n",
       "4    [Subject, indian, springs, deal, book, teco, p...\n",
       "5    [Subject, ehronline, web, address, change, mes...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Tokenization - seperate words by comma \n",
    "df['text'].head(6).apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'label', 'text', 'label_num'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello word hello hello\n",
      "  (0, 1)\t3\n",
      "  (0, 5)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 2)\t1\n",
      "(2, 6)\n"
     ]
    }
   ],
   "source": [
    "message4 = 'hello word hello hello'\n",
    "message5 = 'test etstst tests one hello'\n",
    "print(message4)\n",
    "print\n",
    "\n",
    "#Convert text to matrix of tokens counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow4 = CountVectorizer(analyzer=process_text).fit_transform([[message4], [message5]])\n",
    "print(bow4)\n",
    "\n",
    "print(bow4.shape) #unique words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert collection of text to a matrix of tokens\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "message_bow = CountVectorizer(analyzer=process_text).fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 80% traisning and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(message_bow, df['label_num'], test_size=0.20, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 50381)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the shape of messages_bow\n",
    "message_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the Naive Bayes Classifer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifer = MultinomialNB().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(classifer.predict(X_train))\n",
    "\n",
    "print(Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2940\n",
      "           1       0.98      0.97      0.98      1196\n",
      "\n",
      "    accuracy                           0.99      4136\n",
      "   macro avg       0.99      0.98      0.98      4136\n",
      "weighted avg       0.99      0.99      0.99      4136\n",
      "\n",
      "\n",
      "Confusion MAtrix: \n",
      "[[2918   22]\n",
      " [  30 1166]]\n",
      "Accuracy: \n",
      "0.9874274661508704\n"
     ]
    }
   ],
   "source": [
    "#Evalute the model on the training data\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifer.predict(X_train)\n",
    "print(classification_report(Y_train, pred))\n",
    "print()\n",
    "print('Confusion MAtrix: ')\n",
    "print(confusion_matrix(Y_train, pred))\n",
    "print\n",
    "print(\"Accuracy: \")\n",
    "print(accuracy_score(Y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n",
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(classifer.predict(X_test))\n",
    "\n",
    "print(Y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       732\n",
      "           1       0.95      0.96      0.96       303\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "\n",
      "Confusion MAtrix: \n",
      "[[718  14]\n",
      " [ 13 290]]\n",
      "Accuracy: \n",
      "0.9739130434782609\n"
     ]
    }
   ],
   "source": [
    "pred = classifer.predict(X_test)\n",
    "print(classification_report(Y_test, pred))\n",
    "print()\n",
    "print('Confusion MAtrix: ')\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print\n",
    "print(\"Accuracy: \")\n",
    "print(accuracy_score(Y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
